накомимся с параллелизмом
На данный момент все наши API автотесты выполняются синхронно. Это означает, что каждый тест отправляет запрос к API, получает ответ, выполняет проверки и только после завершения переходит к следующему тесту. Такой подход работает, но при увеличении количества тестов общее время их выполнения значительно возрастает.

Что такое параллельный запуск автотестов?
Параллельный запуск позволяет выполнять несколько API тестов одновременно, распределяя нагрузку между процессорами и потоками. В отличие от UI автотестов, где каждый браузер требует отдельного ядра, API тесты потребляют меньше ресурсов, так как взаимодействуют с сервером через HTTP-запросы, а не эмулируют пользовательские действия в браузере.

При запуске в несколько потоков тесты могут выполняться значительно быстрее. Например, если тестов 100 и они выполняются последовательно за 10 минут, то при параллельном запуске в 5 потоков общее время выполнения может сократиться до 2 минут (при условии, что сервер API выдерживает нагрузку).

Однако стоит учитывать несколько факторов:
 - Ограничения API: некоторые API могут иметь ограничения на частоту запросов (rate limiting), что может привести к ошибкам при слишком интенсивной нагрузке.
 - Зависимости между тестами: если тесты используют одни и те же данные (например, создают и модифицируют один ресурс), при параллельном выполнении возможны конфликты.
 - Ограничения окружения: если API тесты зависят от внешних сервисов (например, базы данных, кэшей, очередей сообщений), параллельное выполнение может увеличить нагрузку на эти компоненты.

Зачем нужен параллельный запуск?
Представьте, что у нас есть 500 API тестов. Если каждый выполняется в среднем 1 секунду, полный прогон займёт более 8 минут. В реальных проектах таких тестов может быть несколько тысяч, и их последовательное выполнение становится слишком долгим.

Параллельный запуск решает эту проблему, сокращая общее время выполнения тестов. Это особенно важно в условиях CI/CD, когда тесты должны проходить быстро, чтобы разработчики могли оперативно получать обратную связь о качестве изменений.

Примечания о параллелизме
Управление зависимостями. Если тесты зависят друг от друга (например, один создаёт ресурс, а другой его проверяет), их выполнение в параллельном режиме может привести к нестабильности. Лучший способ избежать этого — писать независимые тесты, используя фикстуры для подготовки данных.
Нагрузка на сервер API. Параллельный запуск увеличивает количество одновременных запросов. Перед масштабированием тестов убедитесь, что тестовое окружение выдерживает такую нагрузку, а API не ограничивает частоту запросов.
Инструменты и мониторинг. Использование pytest-xdist помогает распределять тесты между процессами, но для лучшего контроля за выполнением полезно включить детализированное логирование и метрики, чтобы отслеживать производительность API во время тестирования.


Вывод
Параллельный запуск — мощный инструмент для ускорения выполнения API автотестов. Он позволяет тестировать быстрее и получать результаты без долгих ожиданий.
Однако перед включением параллелизма важно проанализировать ограничения API, протестировать нагрузку и убедиться, что тесты независимы друг от друга.

Запускаем автотесты параллельно
Ссылки:

Официальная документация pytest-xdist
Для реализации параллельного запуска автотестов с использованием pytest, чаще всего применяется плагин pytest-xdist, который отлично справляется с этой задачей. pytest-xdist — это плагин для pytest, который позволяет выполнять автотесты параллельно, используя несколько ядер процессора (CPUs).

Установка pytest-xdist
Использование плагина pytest-xdist максимально простое. Давайте установим библиотеку pytest-xdist. Для этого в корне проекта autotests-api выполните следующую команду:

pip install pytest-xdist
Запуск автотестов параллельно
Теперь мы готовы запустить автотесты в параллельном режиме, что позволяет значительно ускорить их выполнение за счёт многопоточной обработки. Для этого используется флаг --numprocesses (или его сокращённая версия -n), который определяет, сколько процессов будет запущено одновременно.

Примеры:
--numprocesses=5 – запустит автотесты параллельно на 5 ядрах процессора.
--numprocesses=auto – автоматически использует все доступные ядра на вашей машине.
Важно! Время выполнения тестов может отличаться на несколько секунд в зависимости от мощности процессора, количества доступных ядер и общей загрузки системы. Поэтому все приведённые ниже цифры являются примерными и могут немного отличаться при повторном запуске.

Базовый параллельный запуск
Для начала выполним следующую команду, чтобы запустить тесты параллельно с двумя воркерами:

python -m pytest -m "regression" --numprocesses=2
Допустим, в синхронном режиме 19 автотестов выполнялись примерно за 10–11 секунд:

=============================================================== 19 passed, 32 deselected in 10.17s ===============================================================
Теперь посмотрим, как изменится время выполнения при параллельном запуске:

======================================================================= 19 passed in 9.79s =======================================================================
Как видно, разница незначительна – всего около 0,5–1 секунды.

Увеличиваем количество воркеров
Попробуем теперь запустить тесты с 5 воркерами:

python -m pytest -m "regression" --numprocesses=5
Результат:

======================================================================= 19 passed in 9.87s =======================================================================
Как видите, увеличение количества воркеров не дало значительного ускорения.

Почему не произошло значительного ускорения?
Можно ожидать, что запуск на 5 воркерах приведёт к ускорению выполнения тестов в 2–3 раза, но на практике всё сложнее.

Причины:
Тесты и так выполняются очень быстро

Время выполнения 19 API-тестов в синхронном режиме составляет около 10 секунд, что уже достаточно быстро.
При использовании pytest-xdist часть времени уходит на инициализацию воркеров, загрузку окружения и распределение тестов между процессами.
Если тесты занимают миллисекунды, то параллельный запуск не даст большого прироста.
Затраты на управление воркерами

Чем больше процессов, тем больше времени тратится на их создание, передачу тестов и обработку результатов.
При малом количестве тестов это может даже замедлить процесс вместо ускорения.
Эксперимент: влияние долгих тестов на параллельность
Давайте искусственно замедлим выполнение двух тестов, добавив time.sleep(3), и посмотрим разницу.

Добавляем в test_update_course и test_create_course:

class TestCourses:
    # Остальной код без изменений

    @allure.tag(AllureTag.UPDATE_ENTITY)
    @allure.story(AllureStory.UPDATE_ENTITY)
    @allure.title("Update course")
    @allure.severity(Severity.CRITICAL)
    @allure.sub_suite(AllureStory.UPDATE_ENTITY)
    def test_update_course(self, courses_client: CoursesClient, function_course: CourseFixture):
        time.sleep(3)
        # Остальной код без изменений

    @allure.tag(AllureTag.CREATE_ENTITY)
    @allure.story(AllureStory.CREATE_ENTITY)
    @allure.title("Create course")
    @allure.severity(Severity.BLOCKER)
    @allure.sub_suite(AllureStory.CREATE_ENTITY)
    def test_create_course(
            self,
            courses_client: CoursesClient,
            function_user: UserFixture,
            function_file: FileFixture
    ):
        time.sleep(3)
        # Остальной код без изменений
Запуск в синхронном режиме:

python -m pytest -m "regression"
Результат:

=============================================================== 19 passed, 32 deselected in 16.06s ===============================================================
Запуск в параллельном режиме (2 воркера):

python -m pytest -m "regression" --numprocesses=2
Результат:

====================================================================== 19 passed in 11.17s =======================================================================
Здесь уже видна разница: параллельный запуск дал ускорение на 5 секунд!

Почему так произошло?

В синхронном режиме все тесты выполняются последовательно, и задержка sleep(3) в каждом тесте увеличивает общее время выполнения.
В параллельном режиме тесты распределяются между воркерами, и пока один выполняет долгий тест, другой запускает короткие, что значительно ускоряет процесс.
Выводы
Параллельный запуск эффективен, когда тесты занимают значительное время

Если тесты очень быстрые, то из-за накладных расходов (pytest-xdist) разница будет минимальна.
Если тесты долгие (например, API, UI, интеграционные тесты), то параллельное выполнение даёт заметный прирост скорости.
Оптимальное количество воркеров зависит от тестов и системы

На небольшом количестве тестов 5 воркеров не дадут ощутимого ускорения. Затраты на управление процессами перекрывают потенциальную выгоду.
Но если тестов сотни или тысячи, то при правильном подборе количества воркеров можно значительно сократить время выполнения.
Работа распределяется между воркерами

В синхронном режиме все тесты выполняются последовательно.
В параллельном режиме один воркер может выполнять долгие тесты (например, с sleep(3)), пока другие обрабатывают короткие тесты, тем самым ускоряя процесс.
Как выбрать оптимальное количество воркеров?
Оптимальное число воркеров зависит от нескольких факторов:

Производительность процессора

Если у вас 8 ядер, это не значит, что --numprocesses=8 будет самым эффективным вариантом.
Иногда количество воркеров > числа ядер может приводить к снижению производительности из-за контекстных переключений.
Если тесты короткие, то добавление воркеров не дает прироста, потому что основное время уходит на распределение задач, а не на их выполнение.
Оптимальное количество воркеров — чуть меньше, чем количество ядер процессора.
Тип тестов

Если тесты быстрые – лучшее число воркеров обычно 2–4.
Если тесты медленные (интеграционные, API, UI) – можно увеличивать воркеров, но тестировать на практике.
Количество тестов

Если тестов мало (например, 20–50), разница будет минимальна.
Если тестов сотни или тысячи, параллельный запуск даст значительное ускорение.
Чем больше тестов, тем ощутимее эффект.
Важно! После эксперимента уберите time.sleep(3) из тестов test_update_course и test_create_course, чтобы они работали в нормальном режиме.

Вывод
Параллельное выполнение тестов действительно ускоряет процесс, но его эффективность зависит от количества и скорости самих тестов.

Если тестов мало и они короткие, прирост минимальный.
Если тестов много или они долгие — выигрыш будет значительным.
Число воркеров нужно подбирать, учитывая возможности компьютера.
Фактически, весь параллельный запуск автотестов реализуется установкой библиотеки pytest-xdist и добавлением флага --numprocesses к команде pytest.
Очень важно запомнить этот раздел, так как на собеседованиях часто спрашивают про параллельный запуск автотестов и его работу.
Если вы также расскажете собеседнику, как функционируют pytest-xdist и браузеры с ядрами, вы точно сможете выделиться среди других кандидатов.



==========================================
Работаем с xdist_group в pytest-xdist
==========================================

Существуют ситуации, когда параллельный запуск тестов недопустим, так как он может привести к гонке данных и ложным отрицательным результатам.

Рассмотрим гипотетический пример. У нас есть два автотеста:

test_get_file — проверяет возможность получения данных файла.
test_delete_file — проверяет возможность удаления файла.
Представим, что оба теста одновременно обращаются к одному и тому же файлу на сервере:

test_delete_file удаляет файл.
test_get_file в этот момент пытается получить его содержимое, ожидая, что файл существует.
Если тесты выполняются параллельно, возможна ситуация, когда test_get_file не найдет файл, так как test_delete_file уже удалил его. Это приведет к флаковым (нестабильным) ошибкам и ложным падениям тестов.

Однако при последовательном запуске такой проблемы может не быть — сначала выполнится test_get_file, затем test_delete_file, и гонки данных не возникнет.

Важно! На самом деле, автотесты test_get_file и test_delete_file написаны корректно. Они используют изолированные данные, создаваемые через фикстуры. Однако для примера мы рассматриваем ситуацию, когда изоляция отсутствует, и тесты могут модифицировать одну и ту же сущность (файл), вызывая конфликты при параллельном запуске.

Решение проблемы с помощью pytest-xdist group
Чтобы устранить гонку данных, нужно сделать так, чтобы test_get_file и test_delete_file выполнялись последовательно в одном потоке, даже если остальные тесты продолжают запускаться параллельно.

Для этого в pytest-xdist существует механизм группировки тестов — xdist_group. Он позволяет объединять тесты в группы, внутри которых тесты выполняются синхронно, но при этом сама группа может быть запущена в одном из потоков параллельного выполнения.

Как использовать xdist_group
Добавляем маркировку @pytest.mark.xdist_group(name="files-group") к нашим тестам, чтобы они выполнялись в одном потоке:

class TestFiles:
    # Остальной код без изменений

    @pytest.mark.xdist_group(name="files-group")  # Добавили xdist группу
    @allure.tag(AllureTag.GET_ENTITY)
    @allure.story(AllureStory.GET_ENTITY)
    @allure.title("Get file")
    @allure.severity(Severity.BLOCKER)
    @allure.sub_suite(AllureStory.GET_ENTITY)
    def test_get_file(self, files_client: FilesClient, function_file: FileFixture):
        # Остальной код без изменений

    @pytest.mark.xdist_group(name="files-group")  # Добавили xdist группу
    @allure.tag(AllureTag.DELETE_ENTITY)
    @allure.story(AllureStory.DELETE_ENTITY)
    @allure.title("Delete file")
    @allure.severity(Severity.NORMAL)
    @allure.sub_suite(AllureStory.DELETE_ENTITY)
    def test_delete_file(self, files_client: FilesClient, function_file: FileFixture):
        # Остальной код без изменений
Здесь:

Оба теста объединены в одну группу files-group.
Они будут выполняться синхронно внутри этой группы, но группа может быть запущена параллельно с другими тестами.
Теперь при запуске тестов, даже если используется pytest-xdist, test_get_file и test_delete_file не будут выполняться одновременно:

python -m pytest -m "regression" --numprocesses=2
Если мы посмотрим в логи тестов, то увидим, что оба теста были запущены одним и тем же воркером (gw0), а значит, выполнялись последовательно:

tests/files/test_files.py::TestFiles::test_get_file
[gw0] PASSED tests/files/test_files.py::TestFiles::test_get_file
tests/files/test_files.py::TestFiles::test_delete_file
[gw0] PASSED tests/files/test_files.py::TestFiles::test_delete_file
Общие рекомендации
Название группы (files-group) можно выбрать любое, главное — оно должно отражать смысл группировки тестов.

Но важно понимать, что использование xdist_group — это крайняя мера.

В идеале, параллельные проблемы должны решаться на уровне самих тестов:

Использование уникальных данных (например, создавать отдельные файлы для каждого теста).
Параметризация тестов для работы с разными объектами.
Изоляция тестов с помощью фикстур (function_file, tmp_path, monkeypatch).
Если же ситуация требует строгого порядка выполнения определенных тестов, тогда @pytest.mark.xdist_group может быть оправдан.

Личный опыт
В моей практике пока не было случаев, когда без xdist_group нельзя было обойтись. Как правило, проблема решается изоляцией данных или изменением архитектуры тестов. Однако если у вас есть специфический случай, когда тесты должны выполняться строго последовательно, но при этом другие тесты могут работать параллельно, xdist_group — хороший инструмент.

Важно! Не забудьте удалить маркировки @pytest.mark.xdist_group(name="files-group"), так как наши автотесты работают корректно и в данном случае это излишне. Мы лишь рассмотрели пример, демонстрирующий использование xdist_group.