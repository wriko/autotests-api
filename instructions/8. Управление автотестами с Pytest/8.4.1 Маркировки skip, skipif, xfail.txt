=========================================================
Встроенная pytest маркировка skip
=========================================================
Ссылки:
Официальная документация Pytest по работе с маркировкой skip - https://docs.pytest.org/en/stable/how-to/skipping.html#skipping-test-functions
В pytest существует несколько полезных встроенных маркировок, которые позволяют гибко управлять выполнением тестов в зависимости от условий. Эти маркировки — skip, xfail, и skipif — помогают пропускать или помечать тесты, которые могут не работать в определённых условиях

Маркировка @pytest.mark.skip используется для явного пропуска теста. Она полезна в случаях, когда определённый тест пока не должен запускаться, например, если функциональность временно не работает или ещё не готова.

Пример использования:
    import pytest

    @pytest.mark.skip(reason="Фича в разработке")
    def test_feature_in_development():
        pass

Когда использовать:
 - Фича еще не реализована или находится в разработке.
 - Известно, что тест всегда будет падать, и нужно временно исключить его из прогона. Например, на тестовом окружении произошел сбой с базой данных и пока нет смысла запускать некоторые тесты

При запуске pytest этот тест будет пропущен с указанием причины, и пропуск не считается ошибкой. Посмотрим, как это работает на практике

1. Создадим файл test_pytest_skip.py
.
└── autotests-api/
    └── tests/
        └── test_pytest_skip.py

Внутрь файла test_pytest_skip.py поместим следующий код:

    import pytest


    @pytest.mark.skip(reason="Фича в разработке") # Указываем маркировку, которая пропустит данный автотест
    def test_feature_in_development():
        pass

2.  Запустим автотест
    python -m pytest -k "test_feature_in_development" -s -v
Пример вывода в консоль при успешном запуске команды будет выглядеть так:

    (.venv) username@ip-8-8-8-8 autotests-api % pytest -k "test_feature_in_development" -s -v
    ====================================================================== test session starts =======================================================================
    platform darwin -- Python 3.11.9, pytest-8.3.3, pluggy-1.5.0 -- /Users/username/Documents/autotests-api/.venv/bin/python
    cachedir: .pytest_cache
    rootdir: /Users/username/Documents/autotests-api
    configfile: pytest.ini
    collected 6 items / 3 deselected / 1 selected

    tests/test_pytest_skip.py::test_feature_in_development SKIPPED (Фича в разработке)

    ================================================================ 1 skipped, 5 deselected in 0.05s ================================================================

1. Выбор теста по имени:
 - Команда pytest -k "test_feature_in_development" -s -v запустила тест с фильтром по имени test_feature_in_development.
 - Pytest собрал 4 теста, но только один из них соответствовал этому имени.

2. Метка SKIPPED в логе:
 - Как мы видим в логе, тест test_feature_in_development был пропущен (отмечен как SKIPPED).
 - Причина пропуска указана в скобках: (Фича в разработке). Эта причина была передана в маркировке @pytest.mark.skip(reason="Фича в разработке").

3. Почему тест был пропущен?:
 - Маркировка @pytest.mark.skip позволяет пропускать тесты, которые на данный момент не нужно запускать. Например, если фича ещё не готова или тест требует доработки.
 - В данном случае, тест явно помечен как пропущенный с помощью этой маркировки, и причина была указана как "Фича в разработке".

4. Преимущества использования skip:
 - Документирование причин: Маркировка skip с параметром reason помогает задокументировать, почему тест был пропущен. Это упрощает понимание, почему определённые тесты не запускаются, особенно в больших командах.
 - Гибкость в запуске тестов: Иногда тесты временно не актуальны или находятся в стадии разработки, и маркировка skip позволяет гибко управлять тем, какие тесты запускать, не удаляя их.


================================================================================
Встроенная pytest маркировка skipif
================================================================================
Ссылки:
Официальная документация Pytest по работе с маркировкой skipif - https://docs.pytest.org/en/stable/how-to/skipping.html#id1

Маркировка @pytest.mark.skipif позволяет пропустить тест только при выполнении определённых условий. Например, если тест должен выполняться только на определённой платформе, версии Python, или при наличии внешней зависимости.

Пример использования:

    import pytest
    import sys

    @pytest.mark.skipif(sys.version_info < (3, 8), reason="Требуется Python 3.8 или выше")
    def test_python_version():
        pass

Когда использовать:

Тест зависит от версии библиотеки или языка программирования
Тесты специфичны для одной операционной системы
Тесты можно запускать на каком-то определенном окружении. Например, автотесты можно запускать, только на окружении stable, а на dev, staging, prod нельзя
Тест зависит от определенных настроек. Например, если в настройки автотест был передан определенный параметр
Этот маркер проверяет условие и, если оно истинно, пропускает тест

1. Создадим файл test_pytest_skipif.py
.
└── autotests-api/
    └── tests/
        └── test_pytest_skipif.py
Внутрь файла test_pytest_skipif.py поместим следующий код:

import pytest

SYSTEM_VERSION = "v1.2.0"  # Для примера укажем версию тестируемой системы


@pytest.mark.skipif(
    SYSTEM_VERSION == "v1.3.0",  # Пропустим автотес, если версия системы равна v1.3.0
    reason="Тест не может быть запущен на версии системы v1.3.0"
)
def test_system_version_valid():  # В текущей конфигурации этот тест запустится
    pass


@pytest.mark.skipif(
    SYSTEM_VERSION == "v1.2.0",  # Пропустим автотес, если версия системы равна v1.2.0
    reason="Тест не может быть запущен на версии системы v1.2.0"
)
def test_system_version_invalid():  # Этот автотест не запустится
    pass

2.  Запустим автотесты
    python -m pytest -k "test_system_version" -s -v
Пример вывода в консоль при успешном запуске команды будет выглядеть так:

    (.venv) username@ip-8-8-8-8 autotests-api % python -m pytest -k "test_system_version" -s -v
    ====================================================================== test session starts =======================================================================
    platform darwin -- Python 3.11.9, pytest-8.3.3, pluggy-1.5.0 -- /Users/username/Documents/autotests-api/.venv/bin/python
    cachedir: .pytest_cache
    rootdir: /Users/username/Documents/autotests-api
    configfile: pytest.ini
    collected 8 items / 6 deselected / 2 selected

    tests/test_pytest_skipif.py::test_system_version_valid PASSED
    tests/test_pytest_skipif.py::test_system_version_invalid SKIPPED (Тест не может быть запущен на версии системы v1.2.0)

    =========================================================== 1 passed, 1 skipped, 6 deselected in 0.05s ===========================================================

Что произошло:

 - Тест test_system_version_valid прошёл успешно (PASSED), потому что условие skipif не сработало (версия системы не равна v1.3.0).
 - Тест test_system_version_invalid был пропущен (SKIPPED), потому что условие skipif сработало (версия системы — v1.2.0, что соответствует условию пропуска теста).

Как pytest обрабатывает skipif:

Когда pytest видит маркер skipif, он проверяет условие, переданное в него:
 - Если условие истинно, тест пропускается.
 - Если условие ложно, тест запускается.

В логах вы можете увидеть сообщение о пропуске теста и причину пропуска, которую вы задали в параметре reason. Это помогает легко понять, почему тест был пропущен, что особенно важно при работе с разными конфигурациями систем.


===================================================================================
Встроенная pytest маркировка xfail
===================================================================================
Ссылки:
Официальная документация Pytest по работе с маркировкой xfail - https://docs.pytest.org/en/stable/how-to/skipping.html#xfail-mark-test-functions-as-expected-to-fail

Маркировка @pytest.mark.xfail используется для пометки тестов, которые ожидаемо проваливаются (например, из-за известной ошибки в коде или зависимости). Она позволяет продолжать запуск тестов без остановки на этом этапе и избегать того, чтобы этот провал влиял на общее количество пройденных тестов.

Пример использования:

    import pytest

    @pytest.mark.xfail(reason="Известная ошибка, исправление в следующем релизе")
    def test_known_issue():
        pass

Когда использовать:
 - Есть баг в приложении, который вы знаете и который должен быть исправлен позже.
 - Тесты зависят от стороннего сервиса или ресурса, который временно недоступен.
 - Когда есть проблемы в инфраструктуре, из-за которых тесты могут временно не работать.

Если тест действительно провалится, он будет помечен как xfail, и это не повлияет на итоговый статус выполнения. Если же тест вдруг успешно завершится, pytest пометит это как XPASS, что указывает на неожиданное прохождение теста.

1. Создадим файл test_pytest_xfail.py
.
└── autotests-api/
    └── tests/
        └── test_pytest_xfail.py
Внутрь файла test_pytest_xfail.py поместим следующий код:

import pytest


@pytest.mark.xfail(reason='Найден баг в приложении, из-за которого тест падает с ошибкой')
def test_with_bug():
    assert 1 == 2


@pytest.mark.xfail(reason='Баг уже исправлен, но на тест все еще висит маркировка xfail')
def test_without_bug():
    pass


@pytest.mark.xfail(reason='Внешний сервис временно недоступен')
def test_external_services_is_unavailable():
    assert 1 == 2
2.  Запустим автотест
    python -m pytest -k "test_with_bug or test_without_bug or test_external_services_is_unavailable" -s -v

Пример вывода в консоль при успешном запуске команды будет выглядеть так:

    (.venv) username@ip-8-8-8-8 autotests-api % python -m pytest -k "test_with_bug or test_without_bug or test_external_services_is_unavailable" -s -v
    ====================================================================== test session starts =======================================================================
    platform darwin -- Python 3.11.9, pytest-8.3.3, pluggy-1.5.0 -- /Users/username/Documents/autotests-api/.venv/bin/python
    cachedir: .pytest_cache
    rootdir: /Users/username/Documents/autotests-api
    configfile: pytest.ini
    collected 11 items / 8 deselected / 3 selected

    tests/test_pytest_xfail.py::test_with_bug XFAIL (Найден баг в приложении, из-за которого тест падает с ошибкой)
    tests/test_pytest_xfail.py::test_without_bug XPASS (Баг уже исправлен, но на тест все еще висит маркировка xfail)
    tests/test_pytest_xfail.py::test_external_services_is_unavailable XFAIL (Внешний сервис временно недоступен)

    ========================================================== 8 deselected, 2 xfailed, 1 xpassed in 0.06s ===========================================================

Что произошло:

1. test_with_bug — XFAIL:
Этот тест был помечен как ожидаемо провалившийся, потому что в коде есть известная ошибка:

@pytest.mark.xfail(reason='Найден баг в приложении, из-за которого тест падает с ошибкой')
def test_with_bug():
    assert 1 == 2  # Тест заведомо упадет
Тест провалился (что ожидаемо), и pytest сообщает, что тест был помечен как "XFAIL", что означает "expected failure" (ожидаемая ошибка). Это нормально и не считается ошибкой теста, так как падение теста соответствует нашим ожиданиям. Вывод: XFAIL (Найден баг в приложении, из-за которого тест падает с ошибкой).

2. test_without_bug — XPASS:
Этот тест помечен как ожидаемо провалившийся, но тест прошёл успешно:

@pytest.mark.xfail(reason='Баг уже исправлен, но на тест все еще висит маркировка xfail')
def test_without_bug():
    pass  # Тест не содержит багов и пройдет
Здесь pytest сообщает статус XPASS (unexpected pass — неожиданный успешный результат). Это значит, что тест ожидался как проваленный, но он неожиданно прошел, потому что ошибка была исправлена. Вывод: XPASS (Баг уже исправлен, но на тест все еще висит маркировка xfail).

3. test_external_services_is_unavailable — XFAIL:
Этот тест также помечен как ожидаемо провалившийся из-за временной недоступности внешнего сервиса:

@pytest.mark.xfail(reason='Внешний сервис временно недоступен')
def test_external_services_is_unavailable():
    assert 1 == 2  # Тест заведомо упадет из-за отсутствия сервиса
Как и в первом тесте, pytest правильно отметил его как XFAIL — тест провалился, как и ожидалось, из-за недоступности внешнего сервиса. Вывод: XFAIL (Внешний сервис временно недоступен).

Как работает @pytest.mark.xfail:

Маркер @pytest.mark.xfail указывает, что тест ожидаемо провалится. В случае если тест действительно падает, pytest регистрирует это как XFAIL и не рассматривает это как ошибку. Однако, если тест неожиданно проходит, pytest отметит его как XPASS, что означает, что тест прошел, хотя это не ожидалось.